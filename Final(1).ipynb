{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "04f5d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries for web scraping\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# Get a soup from multiple URLs\n",
    "base_url = 'https://www2.deloitte.com/is/is/profiles/'\n",
    "endings = [\"sif.einarsdottir.html\", \"arnor-egill-hallsson.html\", \"eythor-gudjonsson.html\", \"haraldur-birgisson.html\", \"holmgrimur.bjarnason.html\", \"petur-steinn-gudmundsson.html\", \"Bjorgvin-Ingi-Olafsson.html\", \"einar.haflidi.einarsson.html\", \"arni-thor-vilhelmsson.html\", \"erna.sif.jonsdottir.html\", \"Runolfur_Thor_Sanders.html\", \"helgi-einar-karlsson.html\", \"sigurdur.heidar.steindorsson.html\", \"sunna-dora-einarsdottir.html\", \"ludvik.thrainsson.html\", \"lovisa-anna-finnbjornsdottir.html\", \"Gunnar_Thorvardarson.html\", \"bjorn-vilhjalmsson.html\", \"mariaskuladottir.html\", \"ingvi.bjorn.bergmann.html\", \"Hildur_Gretarsdottir.html\", \"sandra-lind-valsdottir.html\", \"david-stefan-gudmundsson.html\", \"heidar-thor-karlsson.html\", \"Johann-Oskar-Haraldsson.html\", \"johann-oli-eidsson.html\", \"jonas.gestur.jonasson.html\", \"johanna-katrin-palsdottir.html\", \"ulfar-andri-jonasson.html\", \"thorvardur-arnar-agustsson.html\", \"jon-eyfjord-fridriksson.html\", \"erling-tomasson.html\", \"birna-maria.html\", \"thorsteinn.gudjonsson.html\", \"herdis-pala-palsdottir.html\", \"sylvia-rut-saevarsdottir.html\", \"eyglo-sif-sigfusdottir.html\", \"palina.arnadottir.html\", \"fridbjorn-holm-olafsson.html\", \"gudmundur-ingolfsson.html\", \"birna.maria.sigurdardottir.html\", \"gudbjorg-thorsteinsdottir.html\", \"asdis-audunsdottir.html\", \"thordis-bjarnadottir.html\"]\n",
    "i = 0;\n",
    "data.clear()\n",
    "for ending in endings:\n",
    "    i = i+1\n",
    "    url = base_url + ending\n",
    "    r = requests.get(url)\n",
    "    if(r.status_code==200):\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        if soup is not None:\n",
    "            Name = soup.findAll('h1',{'class':'primary-headline white-title'} )\n",
    "            if len(Name) > 0:\n",
    "                Full_Name = Name[0].text\n",
    "            else:\n",
    "                Full_Name = 'not available'\n",
    "            designation = soup.findAll(attrs ={'class':'role1'} )\n",
    "            if len(designation) > 0:\n",
    "                Designation = designation[0].text\n",
    "            else:\n",
    "                Designation = 'not available'\n",
    "            role = soup.findAll('h3',{'class':'tertiary-headline'} )\n",
    "            if len(role) > 0:\n",
    "                Role = role[0].text\n",
    "            else:\n",
    "                Role = 'not available'\n",
    "            contact = soup.findAll(attrs ={'class':'employee-information'} )\n",
    "            if len(contact) > 0:\n",
    "                Contact = contact[0].text.replace(\"\\n\",\"\").replace(\"\\t\",\"\")\n",
    "            else:\n",
    "                Contact = 'not available'\n",
    "            des = soup.findAll(attrs ={'class':'employee-desc custom-rte'} )\n",
    "            if len(des) > 0:\n",
    "                Des = des[0].text\n",
    "            else:\n",
    "                Des = 'not available'\n",
    "            phone = soup.findAll(attrs ={'class':'telephone-btn'} )\n",
    "            if len(phone) > 0:\n",
    "                Phone = phone[0].text.replace(\"\\n\",\"\").replace(\"\\t\",\"\")\n",
    "            else:\n",
    "                Phone = 'not available'\n",
    "            email = soup.findAll('a',{\"data-contacttype\" : \"email\"})\n",
    "            if len(email) > 0:\n",
    "                Email = email[0].text.replace(\"\\n\",\"\").replace(\"\\t\",\"\")\n",
    "            else:\n",
    "                Email = 'not available'\n",
    "            linkedIn = soup.findAll('a',{'title':'LinkedIn'} )\n",
    "            if len(linkedIn) > 0:\n",
    "                LinkedIn = linkedIn[0]['href']\n",
    "            else:\n",
    "                LinkedIn = 'not available'\n",
    "            data.insert(i,[url,Full_Name,Designation,Role,Phone,Email,Contact,Des,LinkedIn])\n",
    "        else:\n",
    "            data.insert(i,[url,'not available','not available','not available','not available','not available','not available','not available','not available'])\n",
    "    else:\n",
    "        data.insert(i,[url,'not available','not available','not available','not available','not available','not available','not available','not available'])\n",
    "df = pd.DataFrame(data,columns = [\"url\",\"Full_Name\",\"Designation\",\"Role\",\"Phone\",\"Email\",\"Contact\",\"Des\",\"LinkedIn\"])\n",
    "df.to_csv('Data10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "65e7321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/in/andy-cotarta-77439a5/\n"
     ]
    }
   ],
   "source": [
    "# Load libraries for web scraping\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# Get a soup from multiple URLs\n",
    "base_url = 'https://www2.deloitte.com/ro/en/profiles/acotarta.html'\n",
    "r = requests.get(base_url)\n",
    "if(r.status_code==200):\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    if soup is not None:\n",
    "        links = soup.findAll('a',{'title':'LinkedIn'} )\n",
    "        print(links[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca495c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
